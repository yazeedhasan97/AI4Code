{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4d21ea-0139-4c44-af1b-6f154c738d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDA VERSION: 11.5\n",
      "__CUDNN VERSION: 8302\n",
      "True\n",
      "None\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "import os, re, sys\n",
    "from pathlib import Path\n",
    "import glob, time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "notebook.tqdm.pandas()\n",
    "tqdm.pandas()\n",
    "\n",
    "import psutil\n",
    "from pyxtension.streams import stream\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 12)\n",
    "\n",
    "\n",
    "import spreprocessers as r\n",
    "import spt_model as m\n",
    "\n",
    "\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "print('__CUDA VERSION:', t.version.cuda)\n",
    "print('__CUDNN VERSION:', t.backends.cudnn.version())\n",
    "print(t.cuda.is_available())\n",
    "if t.cuda.is_available():\n",
    "    print(t.cuda.empty_cache())\n",
    "    print(t.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c957e3c-5f1a-4555-8c92-0b116cabb98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mNumber of notebooks present in train set  =  139256\n",
      "\u001b[94mNumber of notebooks contribute in training =  279\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "data_dir = Path('.')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "models_dir = os.path.join(data_dir, 'pt_models')\n",
    "orders_path = os.path.join(data_dir, 'train_orders.csv')\n",
    "ancestors_path = os.path.join(data_dir, 'train_ancestors.csv')\n",
    "\n",
    "\n",
    "count = len(list(glob.iglob(os.path.join(train_dir, '*.json'))))\n",
    "LOAD_NUM = int(count * 0.002) + 1\n",
    "MULTI = PROCESSORS_COUNT * int(str(LOAD_NUM) [:-2])\n",
    "\n",
    "print(f\"\\033[94mNumber of notebooks present in train set  = \", count)\n",
    "print(f\"\\033[94mNumber of notebooks contribute in training = \", LOAD_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a279a6f-dc9d-4d5c-8622-051151bd7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████| 279/279 [00:02<00:00, 100.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 13633 entries, ('00001756c60be8', '1862f0a6') to ('0087b2bc5ba42e', 'f0b342ad')\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   cell_type  13633 non-null  category\n",
      " 1   source     13633 non-null  object  \n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 806.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00001756c60be8</th>\n",
       "      <th>1862f0a6</th>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many h...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a9e43d6</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038b763d</th>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('igno...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2eefe0ef</th>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0beab1cd</th>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pr...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>39</td>\n",
       "      <td>694</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type  \\\n",
       "id             cell_id              \n",
       "00001756c60be8 1862f0a6      code   \n",
       "               2a9e43d6      code   \n",
       "               038b763d      code   \n",
       "               2eefe0ef      code   \n",
       "               0beab1cd      code   \n",
       "\n",
       "                                                                    source  \\\n",
       "id             cell_id                                                       \n",
       "00001756c60be8 1862f0a6  #  This Python 3 environment comes with many h...   \n",
       "               2a9e43d6  import numpy as np\\nimport pandas as pd\\nimpor...   \n",
       "               038b763d  import warnings\\nwarnings.filterwarnings('igno...   \n",
       "               2eefe0ef      matplotlib.rcParams.update({'font.size': 14})   \n",
       "               0beab1cd  def evaluate_preds(train_true_values, train_pr...   \n",
       "\n",
       "                         n_code_cells  n_markdown_cells  words_count  \\\n",
       "id             cell_id                                                 \n",
       "00001756c60be8 1862f0a6      0.517241          0.482759          140   \n",
       "               2a9e43d6      0.517241          0.482759           55   \n",
       "               038b763d      0.517241          0.482759            3   \n",
       "               2eefe0ef      0.517241          0.482759            2   \n",
       "               0beab1cd      0.517241          0.482759           39   \n",
       "\n",
       "                         letters_count  empty_lines_count  \\\n",
       "id             cell_id                                      \n",
       "00001756c60be8 1862f0a6            930           0.235294   \n",
       "               2a9e43d6            498           0.176471   \n",
       "               038b763d             49           0.000000   \n",
       "               2eefe0ef             45           0.000000   \n",
       "               0beab1cd            694           0.052632   \n",
       "\n",
       "                         comment_lines_count  full_lines_count  \\\n",
       "id             cell_id                                           \n",
       "00001756c60be8 1862f0a6             0.411765          0.352941   \n",
       "               2a9e43d6             0.000000          0.823529   \n",
       "               038b763d             0.000000          1.000000   \n",
       "               2eefe0ef             0.000000          1.000000   \n",
       "               0beab1cd             0.000000          0.947368   \n",
       "\n",
       "                         text_lines_count  tag_lines_count  \n",
       "id             cell_id                                      \n",
       "00001756c60be8 1862f0a6               0.0              0.0  \n",
       "               2a9e43d6               0.0              0.0  \n",
       "               038b763d               0.0              0.0  \n",
       "               2eefe0ef               0.0              0.0  \n",
       "               0beab1cd               0.0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [00:00<00:00, 46834.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aa79b828f141c2a65d1d940f8ab76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many h...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('igno...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2eefe0ef</td>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>0beab1cd</td>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pr...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>39</td>\n",
       "      <td>694</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type  \\\n",
       "0  00001756c60be8  1862f0a6      code   \n",
       "1  00001756c60be8  2a9e43d6      code   \n",
       "2  00001756c60be8  038b763d      code   \n",
       "3  00001756c60be8  2eefe0ef      code   \n",
       "4  00001756c60be8  0beab1cd      code   \n",
       "\n",
       "                                              source  n_code_cells  \\\n",
       "0  #  This Python 3 environment comes with many h...      0.517241   \n",
       "1  import numpy as np\\nimport pandas as pd\\nimpor...      0.517241   \n",
       "2  import warnings\\nwarnings.filterwarnings('igno...      0.517241   \n",
       "3      matplotlib.rcParams.update({'font.size': 14})      0.517241   \n",
       "4  def evaluate_preds(train_true_values, train_pr...      0.517241   \n",
       "\n",
       "   n_markdown_cells  words_count  letters_count  empty_lines_count  \\\n",
       "0          0.482759          140            930           0.235294   \n",
       "1          0.482759           55            498           0.176471   \n",
       "2          0.482759            3             49           0.000000   \n",
       "3          0.482759            2             45           0.000000   \n",
       "4          0.482759           39            694           0.052632   \n",
       "\n",
       "   comment_lines_count  full_lines_count  text_lines_count  tag_lines_count  \\\n",
       "0             0.411765          0.352941               0.0              0.0   \n",
       "1             0.000000          0.823529               0.0              0.0   \n",
       "2             0.000000          1.000000               0.0              0.0   \n",
       "3             0.000000          1.000000               0.0              0.0   \n",
       "4             0.000000          0.947368               0.0              0.0   \n",
       "\n",
       "       rank ancestor_id parent_id  \n",
       "0  0.000000    945aea18       NaN  \n",
       "1  0.034483    945aea18       NaN  \n",
       "2  0.068966    945aea18       NaN  \n",
       "3  0.103448    945aea18       NaN  \n",
       "4  0.137931    945aea18       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 13.185547828674316 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = r.read_all_notebooks_(train_dir, LOAD_NUM, PROCESSORS_COUNT)\n",
    "\n",
    "df = pd.concat(stream(np.array_split(df, PROCESSORS_COUNT)).mpmap(r.extract_features))\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print('-' * 125)\n",
    "\n",
    "# Read Ordering data\n",
    "df_orders = pd.read_csv(\n",
    "    orders_path,\n",
    "    index_col='id',\n",
    ")\n",
    "df_orders['cell_order'] = df_orders['cell_order'].str.split()  # Split the string representation of cell_ids into a list\n",
    "df_orders = df_orders.squeeze(axis=1)\n",
    "\n",
    "\n",
    "# build ranks as integers \n",
    "df = df.join(r.build_ranks_(df_orders, df, PROCESSORS_COUNT))\n",
    "\n",
    "\n",
    "# Read Ancestors data\n",
    "df = df.reset_index().merge(pd.read_csv(ancestors_path,  index_col='id'), on=[\"id\"])\n",
    "\n",
    "# convert integer ranks to percentages \n",
    "df[\"rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "rduration = time.time() - start_time\n",
    "print(f\"Duration {rduration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1af4a5-f509-4de8-8763-fd6bc391a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for percentages \n",
    "INTREST_PERCENT = 0.95\n",
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "VALIDATION_RATIO = 0.15\n",
    "\n",
    "NOT_GENERATED_COLUMNS = ['id', 'cell_id', 'source', 'cell_type', 'rank', 'ancestor_id', 'parent_id', ]\n",
    "MODEL_USELESS = ['id', 'cell_type', 'ancestor_id', 'parent_id', ]\n",
    "GENERATED_COLUMNS_COUNT = len(df.drop(['id', 'cell_id', 'source', 'cell_type', 'rank', 'ancestor_id', 'parent_id', ], axis=1).columns)\n",
    "\n",
    "# BERT_MODEL_NAME = \"microsoft/codebert-base\"\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "# BERT_MODEL_NAME = \"microsoft/graphcodebert-base\"\n",
    "\n",
    "# OPTIMIZER = 'adam'\n",
    "OPTIMIZER = 'nadam'\n",
    "\n",
    "# MAX_LENGTH = int(df[df.cell_type == CODE_TYPE].words_count.quantile(INTREST_PERCENT)) # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "MAX_LENGTH = 196\n",
    "\n",
    "ACCUMULATION_SETPS = 2\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "TOTAL_MAX_LEN = 285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465fc851-7dc4-4f2b-af4d-7f88fced939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [905 906 907 908 909]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many h...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type  \\\n",
       "0  00001756c60be8  1862f0a6      code   \n",
       "1  00001756c60be8  2a9e43d6      code   \n",
       "\n",
       "                                              source  n_code_cells  \\\n",
       "0  #  This Python 3 environment comes with many h...      0.517241   \n",
       "1  import numpy as np\\nimport pandas as pd\\nimpor...      0.517241   \n",
       "\n",
       "   n_markdown_cells  words_count  letters_count  empty_lines_count  \\\n",
       "0          0.482759          140            930           0.235294   \n",
       "1          0.482759           55            498           0.176471   \n",
       "\n",
       "   comment_lines_count  full_lines_count  text_lines_count  tag_lines_count  \\\n",
       "0             0.411765          0.352941               0.0              0.0   \n",
       "1             0.000000          0.823529               0.0              0.0   \n",
       "\n",
       "       rank ancestor_id parent_id  \n",
       "0  0.000000    945aea18       NaN  \n",
       "1  0.034483    945aea18       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ba887b3817</td>\n",
       "      <td>006235ba</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>95</td>\n",
       "      <td>881</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>bde84293</td>\n",
       "      <td>ed1c7969a2900a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008ba887b3817</td>\n",
       "      <td>f643db5c</td>\n",
       "      <td>code</td>\n",
       "      <td>train=pd.read_csv(\"/kaggle/input/covid19-globa...</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>bde84293</td>\n",
       "      <td>ed1c7969a2900a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type  \\\n",
       "0  0008ba887b3817  006235ba      code   \n",
       "1  0008ba887b3817  f643db5c      code   \n",
       "\n",
       "                                              source  n_code_cells  \\\n",
       "0  import numpy as np\\nimport pandas as pd\\nimpor...      0.530612   \n",
       "1  train=pd.read_csv(\"/kaggle/input/covid19-globa...      0.530612   \n",
       "\n",
       "   n_markdown_cells  words_count  letters_count  empty_lines_count  \\\n",
       "0          0.469388           95            881           0.111111   \n",
       "1          0.469388            3            168           0.000000   \n",
       "\n",
       "   comment_lines_count  full_lines_count  text_lines_count  tag_lines_count  \\\n",
       "0             0.037037          0.851852               0.0              0.0   \n",
       "1             0.000000          1.000000               0.0              0.0   \n",
       "\n",
       "       rank ancestor_id       parent_id  \n",
       "0  0.081633    bde84293  ed1c7969a2900a  \n",
       "1  0.122449    bde84293  ed1c7969a2900a  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11107, 16) (2526, 16)\n",
      "24923 6221\n"
     ]
    }
   ],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, test_size=VALIDATION_RATIO, random_state=RANDOM_SEED)\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids_train, ids_valid = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "print(ids_train[:5], ids_valid[:5])\n",
    "\n",
    "# extract code cells for each notebook\n",
    "df_train = df.loc[ids_train, :].reset_index(drop=True)\n",
    "df_valid = df.loc[ids_valid, :].reset_index(drop=True)\n",
    "display(df_train.head(2))\n",
    "display(df_valid.head(2))\n",
    "\n",
    "# dict_cellid_source = dict(zip(df['cell_id'].values, df['source'].values))\n",
    "\n",
    "print(df_train.shape, df_valid.shape) #, len(dict_cellid_source))\n",
    "\n",
    "train_triplets = []\n",
    "val_triplets = []\n",
    "\n",
    "for lst in list(stream(np.array_split(df_train, PROCESSORS_COUNT)).mpmap(r.generate_triplet)):\n",
    "    train_triplets.extend(lst)\n",
    "\n",
    "for lst in list(stream(np.array_split(df_valid, PROCESSORS_COUNT)).mpmap(r.generate_triplet)):\n",
    "    val_triplets.extend(lst)\n",
    "\n",
    "print(len(train_triplets), len(val_triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babd9440-4902-4160-b615-b6311511e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_row:  [1 '2a9e43d6'\n",
      " 'import numpy as np\\nimport pandas as pd\\nimport random\\nfrom sklearn.model_selection import train_test_split, cross_val_score\\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\\nfrom catboost import CatBoostRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.metrics import r2_score as r2\\nfrom sklearn.model_selection import KFold, GridSearchCV\\nfrom datetime import datetime\\nimport matplotlib\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n%matplotlib inline'\n",
      " 0.5172413793103449 0.4827586206896552 55 498 0.17647058823529413 0.0\n",
      " 0.8235294117647058 0.0 0.0 0.034482758620689655]\n",
      "m_row:  [30 '21616367' '*деление признаков на числовые и текстовые*'\n",
      " 0.5172413793103449 0.4827586206896552 6 43 0.0 0.0 1.0 0.0 1.0\n",
      " 0.29310344827586204]\n",
      "c_row:  [1 'f643db5c'\n",
      " 'train=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/train.csv\")\\ntest=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/test.csv\")\\ntrain.head()'\n",
      " 0.5306122448979592 0.46938775510204084 3 168 0.0 0.0 1.0 0.0 0.0\n",
      " 0.12244897959183673]\n",
      "m_row:  [26 'ac1e381b' 'optim k = 3' 0.5306122448979592 0.46938775510204084 6 21\n",
      " 0.0 0.0 1.0 0.0 1.0 0.4489795918367347]\n",
      "(tensor([  101,  1008,  1184, 15290, 29436, 15290, 18947, 10325, 15290,  1194,\n",
      "        16856, 10325, 29744, 19865, 23925, 19259,  1192, 10260,  1202, 10325,\n",
      "        29747, 29436, 19259, 29113, 15290,  1188,  1197, 15290, 23925, 29747,\n",
      "        22919, 19259, 29113, 15290,  1008,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,   101,  1045,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([5.1724e-01, 4.8276e-01, 5.5000e+01, 4.9800e+02, 1.7647e-01, 0.0000e+00,\n",
      "        8.2353e-01, 0.0000e+00, 0.0000e+00, 3.4483e-02, 5.1724e-01, 4.8276e-01,\n",
      "        6.0000e+00, 4.3000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        1.0000e+00, 2.9310e-01]), 0) (tensor([  101, 23569,  5714,  1047,  1027,  1017,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,   101,  1056,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([5.3061e-01, 4.6939e-01, 3.0000e+00, 1.6800e+02, 0.0000e+00, 0.0000e+00,\n",
      "        1.0000e+00, 0.0000e+00, 0.0000e+00, 1.2245e-01, 5.3061e-01, 4.6939e-01,\n",
      "        6.0000e+00, 2.1000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        1.0000e+00, 4.4898e-01]), 0)\n"
     ]
    }
   ],
   "source": [
    "train_ds = m.BDataset(\n",
    "    df_train, \n",
    "    triplts=train_triplets,\n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "val_ds = m.BDataset(\n",
    "    df_valid, \n",
    "    triplts=val_triplets,\n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN,  \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "print(train_ds[0], val_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22aeb246-64fd-4dfc-a1b9-54e0ffed9f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001A10C162CE0> <torch.utils.data.dataloader.DataLoader object at 0x000001A10C162E90>\n"
     ]
    }
   ],
   "source": [
    "# build code DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    pin_memory=False, \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    pin_memory=False, \n",
    "    drop_last=False\n",
    ")\n",
    "print(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0141af75-7176-4bef-bcb3-9506ccb58991",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3452801a-fc2f-4270-b347-22e68b74457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3115 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught UnicodeEncodeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"E:\\AI4Code\\spt_model.py\", line 331, in __getitem__\n    print('m_row: ', m_row)\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py\", line 19, in encode\n    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\nUnicodeEncodeError: 'charmap' codec can't encode characters in position 20-31: character maps to <undefined>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m########################################################################################################################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mBModel(\n\u001b[0;32m      3\u001b[0m     BERT_MODEL_NAME, \n\u001b[0;32m      4\u001b[0m     GENERATED_COLUMNS_COUNT \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      5\u001b[0m )\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m----> 7\u001b[0m model, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACCUMULATION_SETPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBERT_MODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPTIMIZER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msingle_bert_checkpoint.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_valid\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrank(pct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n",
      "File \u001b[1;32mE:\\AI4Code\\spt_model.py:466\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, epochs, patience, accumulation_steps, opt, model_name, path)\u001b[0m\n\u001b[0;32m    463\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    464\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tbar):\n\u001b[0;32m    467\u001b[0m     inputs, target \u001b[38;5;241m=\u001b[39m read_data(data)\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(tbar) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1250\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:456\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    452\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(msg)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught UnicodeEncodeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"E:\\AI4Code\\spt_model.py\", line 331, in __getitem__\n    print('m_row: ', m_row)\n  File \"C:\\Users\\yazee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py\", line 19, in encode\n    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\nUnicodeEncodeError: 'charmap' codec can't encode characters in position 20-31: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "model = m.BModel(\n",
    "    BERT_MODEL_NAME, \n",
    "    GENERATED_COLUMNS_COUNT * 2\n",
    ").cuda()\n",
    "\n",
    "model, y_pred = m.train(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epochs=EPOCHS, \n",
    "    accumulation_steps=ACCUMULATION_SETPS, \n",
    "    model_name=BERT_MODEL_NAME,\n",
    "    opt=OPTIMIZER, \n",
    "    path=os.path.join(models_dir, 'single_bert_checkpoint.pt')\n",
    ")\n",
    "\n",
    "df_valid[\"pred\"] = df_valid.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "df_valid[\"pred\"] = y_pred\n",
    "########################################################################################################################\n",
    "\n",
    "y_dummy = df_valid.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print('Final accuracy for code is:', r.kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "\n",
    "# best_model_state = deepcopy(code_model.state_dict())\n",
    "# t.save(best_model_state, f'./pt_models/code_model_state_dict.pt')\n",
    "# t.save(code_model, f'./pt_models/code_model.pt')\n",
    "\n",
    "rduration = time.time() - start_time\n",
    "print(f\"\\nDuration {rduration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba1916-9244-4a65-b3e2-8cd7e100c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1d626-5a52-4013-89eb-6d1d519c149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print(f\"\\033[94mNumber of notebooks present in test set  = \", len(list(glob.iglob(os.path.join(test_dir, '*.json')))))\n",
    "\n",
    "df_test = r.read_all_notebooks_(test_dir, 4, 2, desc=\"Tests NBs\")\n",
    "\n",
    "df_test = r.extract_features(df_test).reset_index()\n",
    "df_test['rank'] = 0\n",
    "\n",
    "MODEL_USELESS = ['id', 'cell_id', 'cell_type', ]\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_MAX_LEN = 256\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "df_test['rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'single_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=MAX_LENGTH, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=df_test, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "df_test = df_test.sort_values(\"rank\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "df_test.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "display(df_test.head())\n",
    "\n",
    "# df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b7c86-0c4f-4d1f-b9cb-fb02b0a4364d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb418e-c1f6-4869-9e3c-1ab06ca93679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d14459-ef30-489c-8018-7ad129fbcf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f15cc8-a69c-4dab-b1ab-174ed13d5b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
