{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4d21ea-0139-4c44-af1b-6f154c738d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "import os, re, sys\n",
    "from pathlib import Path\n",
    "import glob, time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "notebook.tqdm.pandas()\n",
    "tqdm.pandas()\n",
    "\n",
    "import psutil\n",
    "from pyxtension.streams import stream\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 12)\n",
    "\n",
    "\n",
    "import preprocessers as r\n",
    "import pt_model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c957e3c-5f1a-4555-8c92-0b116cabb98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mNumber of notebooks present in train set  =  139256\n"
     ]
    }
   ],
   "source": [
    "LOAD_NUM = 100\n",
    "RANDOM_SEED = 42\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "MULTI = PROCESSORS_COUNT * int(str(LOAD_NUM) [:-2])\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "data_dir = Path('.')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "models_dir = os.path.join(data_dir, 'pt_models')\n",
    "orders_path = os.path.join(data_dir, 'train_orders.csv')\n",
    "ancestors_path = os.path.join(data_dir, 'train_ancestors.csv')\n",
    "\n",
    "# shutil.rmtree(models_dir)\n",
    "# if not os.path.exists(models_dir):\n",
    "#     os.mkdir(models_dir)\n",
    "\n",
    "print(f\"\\033[94mNumber of notebooks present in train set  = \", len(list(glob.iglob(os.path.join(train_dir, '*.json')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a279a6f-dc9d-4d5c-8622-051151bd7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4427 entries, ('00001756c60be8', '1862f0a6') to ('002bcc9e2f9077', 'cffa684c')\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   cell_type  4427 non-null   category\n",
      " 1   source     4427 non-null   object  \n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 220.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00001756c60be8</th>\n",
       "      <th>1862f0a6</th>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many h...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a9e43d6</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038b763d</th>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('igno...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2eefe0ef</th>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0beab1cd</th>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pr...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>39</td>\n",
       "      <td>694</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type  \\\n",
       "id             cell_id              \n",
       "00001756c60be8 1862f0a6      code   \n",
       "               2a9e43d6      code   \n",
       "               038b763d      code   \n",
       "               2eefe0ef      code   \n",
       "               0beab1cd      code   \n",
       "\n",
       "                                                                    source  \\\n",
       "id             cell_id                                                       \n",
       "00001756c60be8 1862f0a6  #  This Python 3 environment comes with many h...   \n",
       "               2a9e43d6  import numpy as np\\nimport pandas as pd\\nimpor...   \n",
       "               038b763d  import warnings\\nwarnings.filterwarnings('igno...   \n",
       "               2eefe0ef      matplotlib.rcParams.update({'font.size': 14})   \n",
       "               0beab1cd  def evaluate_preds(train_true_values, train_pr...   \n",
       "\n",
       "                         n_code_cells  n_markdown_cells  words_count  \\\n",
       "id             cell_id                                                 \n",
       "00001756c60be8 1862f0a6      0.517241          0.482759          140   \n",
       "               2a9e43d6      0.517241          0.482759           55   \n",
       "               038b763d      0.517241          0.482759            3   \n",
       "               2eefe0ef      0.517241          0.482759            2   \n",
       "               0beab1cd      0.517241          0.482759           39   \n",
       "\n",
       "                         letters_count  empty_lines_count  \\\n",
       "id             cell_id                                      \n",
       "00001756c60be8 1862f0a6            930           0.235294   \n",
       "               2a9e43d6            498           0.176471   \n",
       "               038b763d             49           0.000000   \n",
       "               2eefe0ef             45           0.000000   \n",
       "               0beab1cd            694           0.052632   \n",
       "\n",
       "                         comment_lines_count  full_lines_count  \\\n",
       "id             cell_id                                           \n",
       "00001756c60be8 1862f0a6             0.411765          0.352941   \n",
       "               2a9e43d6             0.000000          0.823529   \n",
       "               038b763d             0.000000          1.000000   \n",
       "               2eefe0ef             0.000000          1.000000   \n",
       "               0beab1cd             0.000000          0.947368   \n",
       "\n",
       "                         text_lines_count  tag_lines_count  \n",
       "id             cell_id                                      \n",
       "00001756c60be8 1862f0a6               0.0              0.0  \n",
       "               2a9e43d6               0.0              0.0  \n",
       "               038b763d               0.0              0.0  \n",
       "               2eefe0ef               0.0              0.0  \n",
       "               0beab1cd               0.0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9a3ae8aa214854b851ed37b0781c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many h...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('igno...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2eefe0ef</td>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>0beab1cd</td>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pr...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>39</td>\n",
       "      <td>694</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type  \\\n",
       "0  00001756c60be8  1862f0a6      code   \n",
       "1  00001756c60be8  2a9e43d6      code   \n",
       "2  00001756c60be8  038b763d      code   \n",
       "3  00001756c60be8  2eefe0ef      code   \n",
       "4  00001756c60be8  0beab1cd      code   \n",
       "\n",
       "                                              source  n_code_cells  \\\n",
       "0  #  This Python 3 environment comes with many h...      0.517241   \n",
       "1  import numpy as np\\nimport pandas as pd\\nimpor...      0.517241   \n",
       "2  import warnings\\nwarnings.filterwarnings('igno...      0.517241   \n",
       "3      matplotlib.rcParams.update({'font.size': 14})      0.517241   \n",
       "4  def evaluate_preds(train_true_values, train_pr...      0.517241   \n",
       "\n",
       "   n_markdown_cells  words_count  letters_count  empty_lines_count  \\\n",
       "0          0.482759          140            930           0.235294   \n",
       "1          0.482759           55            498           0.176471   \n",
       "2          0.482759            3             49           0.000000   \n",
       "3          0.482759            2             45           0.000000   \n",
       "4          0.482759           39            694           0.052632   \n",
       "\n",
       "   comment_lines_count  full_lines_count  text_lines_count  tag_lines_count  \\\n",
       "0             0.411765          0.352941               0.0              0.0   \n",
       "1             0.000000          0.823529               0.0              0.0   \n",
       "2             0.000000          1.000000               0.0              0.0   \n",
       "3             0.000000          1.000000               0.0              0.0   \n",
       "4             0.000000          0.947368               0.0              0.0   \n",
       "\n",
       "       rank ancestor_id parent_id  \n",
       "0  0.000000    945aea18       NaN  \n",
       "1  0.034483    945aea18       NaN  \n",
       "2  0.068966    945aea18       NaN  \n",
       "3  0.103448    945aea18       NaN  \n",
       "4  0.137931    945aea18       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 13.233138799667358 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = r.read_all_notebooks_(train_dir, LOAD_NUM, PROCESSORS_COUNT)\n",
    "\n",
    "df = pd.concat(stream(np.array_split(df, PROCESSORS_COUNT)).mpmap(r.extract_features))\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print('-' * 125)\n",
    "\n",
    "# Read Ordering data\n",
    "df_orders = pd.read_csv(\n",
    "    orders_path,\n",
    "    index_col='id',\n",
    ")\n",
    "df_orders['cell_order'] = df_orders['cell_order'].str.split()  # Split the string representation of cell_ids into a list\n",
    "df_orders = df_orders.squeeze(axis=1)\n",
    "\n",
    "\n",
    "# build ranks as integers \n",
    "df = df.join(r.build_ranks_(df_orders, df, PROCESSORS_COUNT))\n",
    "\n",
    "\n",
    "# Read Ancestors data\n",
    "df = df.reset_index().merge(pd.read_csv(ancestors_path,  index_col='id'), on=[\"id\"])\n",
    "\n",
    "# convert integer ranks to percentages \n",
    "df[\"rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "rduration = time.time() - start_time\n",
    "print(f\"Duration {rduration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3eb2ab-052d-4dd0-9ac4-03da4c7e9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1af4a5-f509-4de8-8763-fd6bc391a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for percentages \n",
    "INTREST_PERCENT = 0.95\n",
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "VALIDATION_RATIO = 0.2\n",
    "\n",
    "NOT_GENERATED_COLUMNS = ['id', 'cell_id', 'source', 'cell_type', 'rank', 'ancestor_id', 'parent_id', ]\n",
    "MODEL_USELESS = ['id', 'cell_id', 'cell_type', 'ancestor_id', 'parent_id', ]\n",
    "GENERATED_COLUMNS_COUNT = len(df.drop(['id', 'cell_id', 'source', 'cell_type', 'rank', 'ancestor_id', 'parent_id', ], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dff9dd-f411-4717-b440-630ba647d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfdfba0-6e8e-4195-89b7-50787ffb9bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDA VERSION: 11.5\n",
      "__CUDNN VERSION: 8302\n",
      "True\n",
      "None\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "print('__CUDA VERSION:', t.version.cuda)\n",
    "print('__CUDNN VERSION:', t.backends.cudnn.version())\n",
    "print(t.cuda.is_available())\n",
    "print(t.cuda.empty_cache())\n",
    "print(t.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465fc851-7dc4-4f2b-af4d-7f88fced939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [151 152 153 154 155]\n"
     ]
    }
   ],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, test_size=VALIDATION_RATIO, random_state=RANDOM_SEED)\n",
    "\n",
    "def extract_items(ids, data, cell_type):\n",
    "    tmp = data.loc[ids, :].reset_index(drop=True)\n",
    "    return tmp[tmp.cell_type == cell_type]\n",
    "\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids_train, ids_valid = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "print(ids_train[:5], ids_valid[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5fe8bb4-c478-4195-ad2d-af97da41b4b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3452801a-fc2f-4270-b347-22e68b74457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words counts to cover 0.95 is: 95\n",
      "Total number of fetures output from bert: 104\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# BERT_MODEL_NAME = \"microsoft/codebert-base\"\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "OPTIMIZER = 'adam' # 'nadam'\n",
    "\n",
    "MAX_LENGTH = int(df[df.cell_type == CODE_TYPE].words_count.quantile(INTREST_PERCENT)) # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "BERT_OUTPUT_FEATURES = MAX_LENGTH + GENERATED_COLUMNS_COUNT\n",
    "\n",
    "\n",
    "print(\"Words counts to cover {percent} is: {count}\".format(percent=INTREST_PERCENT, count=MAX_LENGTH))\n",
    "print(f'Total number of fetures output from bert: {BERT_OUTPUT_FEATURES}')\n",
    "\n",
    "ACCUMULATION_SETPS = 3\n",
    "\n",
    "# model run\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "TOTAL_MAX_LEN = 256\n",
    "\n",
    "\n",
    "# extract code cells for each notebook\n",
    "code_df_train = extract_items(ids_train, df, CODE_TYPE)\n",
    "code_df_valid = extract_items(ids_valid, df, CODE_TYPE)\n",
    "# print(code_df_train[:5], code_df_valid[:5])\n",
    "\n",
    "# build code Dataset\n",
    "cd_train_ds = m.Dataset(\n",
    "    code_df_train, \n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "cd_val_ds = m.Dataset(\n",
    "    code_df_valid, \n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN,  \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "# print(cd_train_ds[0], cd_val_ds[0])\n",
    "\n",
    "# build code DataLoader\n",
    "cd_train_loader = DataLoader(cd_train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=PROCESSORS_COUNT, pin_memory=False, drop_last=True)\n",
    "cd_val_loader = DataLoader(cd_val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=PROCESSORS_COUNT, pin_memory=False, drop_last=False)\n",
    "# print(cd_train_loader, cd_val_loader)\n",
    "\n",
    "########################################################################################################################\n",
    "code_model = m.BModel(\n",
    "    BERT_MODEL_NAME, \n",
    "    # BERT_OUTPUT_FEATURES\n",
    ").cuda()\n",
    "\n",
    "code_model, code_y_pred = m.train(\n",
    "    code_model, \n",
    "    cd_train_loader, \n",
    "    cd_val_loader, \n",
    "    epochs=EPOCHS, \n",
    "    accumulation_steps=ACCUMULATION_SETPS, \n",
    "    model_name=BERT_MODEL_NAME,\n",
    "    opt=OPTIMIZER, \n",
    "    path=os.path.join(models_dir, 'code_bert_checkpoint.pt')\n",
    ")\n",
    "\n",
    "code_df_valid[\"bcpred\"] = code_df_valid.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "code_df_valid[\"bcpred\"] = code_y_pred\n",
    "\n",
    "# code_gmodel = m.GModel(gc_count=GENERATED_COLUMNS_COUNT).cuda()\n",
    "# code_gmodel, cd_y_gpred = m.train(code_gmodel, cd_train_loader, cd_val_loader, epochs=10, patience=3, path='pt_models/code_gen_checkpoint.pt')\n",
    "\n",
    "# code_df_valid[\"gcpred\"] = code_df_train.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "# code_df_valid[\"gcpred\"] = cd_y_gpred\n",
    "\n",
    "# code_df_valid['pred'] = (code_df_valid[\"bcpred\"] + code_df_valid[\"gcpred\"]) / 2.002\n",
    "code_df_valid['pred'] = code_df_valid[\"bcpred\"]\n",
    "########################################################################################################################\n",
    "code_y_dummy = code_df_valid.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print('Final accuracy for code is:', r.kendall_tau(df_orders.loc[code_y_dummy.index], code_y_dummy))\n",
    "\n",
    "# best_model_state = deepcopy(code_model.state_dict())\n",
    "# t.save(best_model_state, f'./pt_models/code_model_state_dict.pt')\n",
    "# t.save(code_model, f'./pt_models/code_model.pt')\n",
    "\n",
    "rduration = time.time() - start_time\n",
    "print(f\"\\nDuration {rduration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba1916-9244-4a65-b3e2-8cd7e100c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee91c22b-f832-4691-958c-2712870b8d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words counts to cover 0.95 is: 116\n",
      "Total number of fetures output from bert: 125\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "MAX_LENGTH = int(df[df.cell_type == MKDN_TYPE].words_count.quantile(INTREST_PERCENT)) \n",
    "\n",
    "# SHUFFLE_SIZE = len(df[df.cell_type == MKDN_TYPE].n_total_cells[df.n_total_cells <= SHUFFE_REF]) \n",
    "BERT_OUTPUT_FEATURES = MAX_LENGTH + GENERATED_COLUMNS_COUNT\n",
    "\n",
    "\n",
    "print(\"Words counts to cover {percent} is: {count}\".format(percent=INTREST_PERCENT, count=MAX_LENGTH))\n",
    "# print(\"Shuffle size by {percent} count is: {count}\".format(percent=SHUFFLE_INTREST_PERCENT, count=SHUFFLE_SIZE))\n",
    "print(f'Total number of fetures output from bert: {BERT_OUTPUT_FEATURES}')\n",
    "\n",
    "ACCUMULATION_SETPS = 3\n",
    "\n",
    "# model run\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "TOTAL_MAX_LEN = 256\n",
    "\n",
    "\n",
    "# extract markdown cells for each notebook\n",
    "mkdn_df_train = extract_items(ids_train, df, MKDN_TYPE)\n",
    "mkdn_df_valid = extract_items(ids_valid, df, MKDN_TYPE)\n",
    "# print(mkdn_df_train[:5], mkdn_df_valid[:5])\n",
    "\n",
    "\n",
    "# build markdown Dataset\n",
    "mkdn_train_ds = m.Dataset(\n",
    "    mkdn_df_train, \n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "mkdn_val_ds = m.Dataset(\n",
    "    mkdn_df_valid, \n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN,  \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "# print(mkdn_train_ds[0], mkdn_val_ds[0])\n",
    "\n",
    "# build markdown DataLoader\n",
    "mkdn_train_loader = DataLoader(mkdn_train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=PROCESSORS_COUNT, pin_memory=False, drop_last=True)\n",
    "mkdn_val_loader = DataLoader(mkdn_val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=PROCESSORS_COUNT, pin_memory=False, drop_last=False)\n",
    "# print(mkdn_train_loader, mkdn_val_loader)\n",
    "\n",
    "########################################################################################################################\n",
    "mkdn_model = m.BModel(\n",
    "    BERT_MODEL_NAME, \n",
    "    # BERT_OUTPUT_FEATURES\n",
    ").cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mkdn_model, mkdn_y_pred = m.train(\n",
    "    mkdn_model, \n",
    "    mkdn_train_loader, \n",
    "    mkdn_val_loader, \n",
    "    epochs=EPOCHS, \n",
    "    accumulation_steps=ACCUMULATION_SETPS, \n",
    "    model_name=BERT_MODEL_NAME,\n",
    "    opt='nadam', \n",
    "    path=os.path.join(models_dir, 'markdown_bert_checkpoint.pt')\n",
    ")\n",
    "\n",
    "mkdn_df_valid[\"bmpred\"] = mkdn_df_train.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "mkdn_df_valid[\"bmpred\"] = mkdn_y_pred\n",
    "\n",
    "# mkdn_gmodel = m.GModel(gc_count=GENERATED_COLUMNS_COUNT).cuda()\n",
    "# mkdn_gmodel, mkdn_y_gpred = m.train(mkdn_gmodel, mkdn_train_loader, mkdn_val_loader, epochs=10, patience=3, path='pt_models/mkdn_gen_checkpoint.pt')\n",
    "\n",
    "# mkdn_df_valid[\"gmpred\"] = mkdn_df_train.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "# mkdn_df_valid[\"gmpred\"] = mkdn_y_gpred\n",
    "\n",
    "\n",
    "# mkdn_df_valid['pred'] = (mkdn_df_valid[\"bmpred\"] + mkdn_df_valid[\"gmpred\"]) / 2.002\n",
    "mkdn_df_valid['pred'] = mkdn_df_valid[\"bmpred\"]\n",
    "########################################################################################################################\n",
    "\n",
    "mkdn_y_dummy = mkdn_df_valid.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print('Final accuracy for markdown is:', r.kendall_tau(df_orders.loc[mkdn_y_dummy.index], mkdn_y_dummy))\n",
    "\n",
    "# # best_model_state = deepcopy(mkdn_model.state_dict())\n",
    "# # t.save(best_model_state, f'./pt_models/markdown_model_state_dict.pt')\n",
    "# # t.save(mkdn_model, f'./pt_models/markdown_model.pt')\n",
    "\n",
    "rduration = time.time() - start_time\n",
    "print(f\"\\nDuration {rduration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0715a-ae21-439c-9eed-3735e2540ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3aed180-0fea-44b4-911b-70b439817dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:29<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:29<00:00,  1.68it/s]\n",
      "Final total accuracy is: 0.08832626051931236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "0001bdd4021779    [3fdc37be, 38310c80, 7fde4f04, ad7679ef, 0a1a7...\n",
       "0007f21ee357b5    [40a1a0ce, e68e6c44, 7a5263a6, 28660f19, 4d264...\n",
       "000890decea38e    [ec7e340c, d1b548da, b444859f, 3d243130, d46fa...\n",
       "0008ba887b3817    [006235ba, 12f6aba1, 3231cc0c, 5bd9ae73, bf698...\n",
       "000af347c31e72    [6fa470b3, 6c44e9ba, a01ba7ea, 98d1cdf3, 00c42...\n",
       "Name: cell_id, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_MAX_LEN = 256\n",
    "\n",
    "code_df_valid['rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'code_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=95, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=code_df_valid, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "mkdn_df_valid['rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'markdown_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=116, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=mkdn_df_valid, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "vres_df = pd.concat([mkdn_df_valid, code_df_valid], ignore_index=True, ).sort_values(\"rank\").groupby(\"id\")[\"cell_id\"].apply(list)\n",
    "print('Final total accuracy is:', r.kendall_tau(df_orders.loc[vres_df.index], vres_df))\n",
    "\n",
    "display(vres_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5c0cd-8d19-4588-b19b-80e9aca01a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea1d626-5a52-4013-89eb-6d1d519c149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mNumber of notebooks present in test set  =  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tests NBs: 100%|██████████| 4/4 [00:00<00:00, 4007.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 89 entries, ('0009d135ece78d', 'ddfd239c') to ('0028856e09c5b7', 'eb293dfc')\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   cell_type  89 non-null     category\n",
      " 1   source     89 non-null     object  \n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "None\n",
      "Extract Code Cells Counts\n",
      "Extract Markdown Cells Counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:29<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yazee\\AppData\\Local\\Temp\\ipykernel_14212\\1402259125.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[df_test.cell_type == CODE_TYPE]['rank'] = m.predict(\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:29<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yazee\\AppData\\Local\\Temp\\ipykernel_14212\\1402259125.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[df_test.cell_type == MKDN_TYPE]['rank'] = m.predict(\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print(f\"\\033[94mNumber of notebooks present in test set  = \", len(list(glob.iglob(os.path.join(test_dir, '*.json')))))\n",
    "\n",
    "df_test = r.read_all_notebooks_(test_dir, 4, 2, desc=\"Tests NBs\")\n",
    "\n",
    "df_test = r.extract_features(df_test).reset_index()\n",
    "df_test['rank'] = 0\n",
    "\n",
    "MODEL_USELESS = ['id', 'cell_id', 'cell_type', ]\n",
    "\n",
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_MAX_LEN = 256\n",
    "\n",
    "df_test.loc[df_test.cell_type == CODE_TYPE, 'rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'code_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=95, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=df_test[df_test.cell_type == CODE_TYPE], \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "df_test.loc[df_test.cell_type == MKDN_TYPE, 'rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'markdown_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=116, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=df_test[df_test.cell_type == MKDN_TYPE], \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "df_test = df_test.sort_values(\"rank\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "df_test.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "display(df_test.head())\n",
    "\n",
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b7c86-0c4f-4d1f-b9cb-fb02b0a4364d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb418e-c1f6-4869-9e3c-1ab06ca93679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d14459-ef30-489c-8018-7ad129fbcf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f15cc8-a69c-4dab-b1ab-174ed13d5b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
