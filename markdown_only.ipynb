{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4d21ea-0139-4c44-af1b-6f154c738d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDA VERSION: 11.5\n",
      "__CUDNN VERSION: 8302\n",
      "True\n",
      "None\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, os, glob, psutil, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "notebook.tqdm.pandas()\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from pyxtension.streams import stream\n",
    "import swifter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import nltk\n",
    "try:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "except:\n",
    "    print(\"Could't donlowd requaired text data\")\n",
    "\n",
    "print('__CUDA VERSION:', torch.version.cuda)\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.empty_cache())\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    \n",
    "\n",
    "\n",
    "import markdown_only as mol\n",
    "#import pt_model as m\n",
    "#import strongercodebase_v2 as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c957e3c-5f1a-4555-8c92-0b116cabb98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mNumber of notebooks present in train set  =  139256\n",
      "\u001b[94mNumber of notebooks contribute in training =  100\n"
     ]
    }
   ],
   "source": [
    "LOAD_NUM = 100\n",
    "RANDOM_SEED = 42\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "MULTI = PROCESSORS_COUNT * int(str(LOAD_NUM) [:-2])\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "data_dir = Path('.')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "models_dir = os.path.join(data_dir, 'pt_models')\n",
    "orders_path = os.path.join(data_dir, 'train_orders.csv')\n",
    "ancestors_path = os.path.join(data_dir, 'train_ancestors.csv')\n",
    "\n",
    "\n",
    "\n",
    "# shutil.rmtree(models_dir)\n",
    "# if not os.path.exists(models_dir):\n",
    "#     os.mkdir(models_dir)\n",
    "count = len(list(glob.iglob(os.path.join(train_dir, '*.json'))))\n",
    "# LOAD_NUM = int(count * 0.1) + 1\n",
    "print(f\"\\033[94mNumber of notebooks present in train set  = \", count)\n",
    "print(f\"\\033[94mNumber of notebooks contribute in training = \", LOAD_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a279a6f-dc9d-4d5c-8622-051151bd7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████| 100/100 [00:00<00:00, 20056.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00001756c60be8</th>\n",
       "      <th>1862f0a6</th>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a9e43d6</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport random\\nfrom sklearn.model_selection import train_test_split, cross_...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038b763d</th>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2eefe0ef</th>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0beab1cd</th>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>39</td>\n",
       "      <td>694</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type                                                                                                                   source  n_code_cells  \\\n",
       "id             cell_id                                                                                                                                                     \n",
       "00001756c60be8 1862f0a6      code  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...      0.517241   \n",
       "               2a9e43d6      code  import numpy as np\\nimport pandas as pd\\nimport random\\nfrom sklearn.model_selection import train_test_split, cross_...      0.517241   \n",
       "               038b763d      code                                                                       import warnings\\nwarnings.filterwarnings('ignore')      0.517241   \n",
       "               2eefe0ef      code                                                                            matplotlib.rcParams.update({'font.size': 14})      0.517241   \n",
       "               0beab1cd      code  def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...      0.517241   \n",
       "\n",
       "                         n_markdown_cells  words_count  letters_count  empty_lines_count  comment_lines_count  full_lines_count  text_lines_count  tag_lines_count  \n",
       "id             cell_id                                                                                                                                              \n",
       "00001756c60be8 1862f0a6          0.482759          140            930           0.235294             0.411765          0.352941               0.0              0.0  \n",
       "               2a9e43d6          0.482759           55            498           0.176471             0.000000          0.823529               0.0              0.0  \n",
       "               038b763d          0.482759            3             49           0.000000             0.000000          1.000000               0.0              0.0  \n",
       "               2eefe0ef          0.482759            2             45           0.000000             0.000000          1.000000               0.0              0.0  \n",
       "               0beab1cd          0.482759           39            694           0.052632             0.000000          0.947368               0.0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 49431.99it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72477bac1a14887868309acc8bc6d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>words_count</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>empty_lines_count</th>\n",
       "      <th>comment_lines_count</th>\n",
       "      <th>full_lines_count</th>\n",
       "      <th>text_lines_count</th>\n",
       "      <th>tag_lines_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>140</td>\n",
       "      <td>930</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport random\\nfrom sklearn.model_selection import train_test_split, cross_...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>55</td>\n",
       "      <td>498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2eefe0ef</td>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>0beab1cd</td>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>39</td>\n",
       "      <td>694</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source  n_code_cells  \\\n",
       "0  00001756c60be8  1862f0a6      code  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...      0.517241   \n",
       "1  00001756c60be8  2a9e43d6      code  import numpy as np\\nimport pandas as pd\\nimport random\\nfrom sklearn.model_selection import train_test_split, cross_...      0.517241   \n",
       "2  00001756c60be8  038b763d      code                                                                       import warnings\\nwarnings.filterwarnings('ignore')      0.517241   \n",
       "3  00001756c60be8  2eefe0ef      code                                                                            matplotlib.rcParams.update({'font.size': 14})      0.517241   \n",
       "4  00001756c60be8  0beab1cd      code  def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...      0.517241   \n",
       "\n",
       "   n_markdown_cells  words_count  letters_count  empty_lines_count  comment_lines_count  full_lines_count  text_lines_count  tag_lines_count      rank ancestor_id parent_id  \n",
       "0          0.482759          140            930           0.235294             0.411765          0.352941               0.0              0.0  0.000000    945aea18       NaN  \n",
       "1          0.482759           55            498           0.176471             0.000000          0.823529               0.0              0.0  0.034483    945aea18       NaN  \n",
       "2          0.482759            3             49           0.000000             0.000000          1.000000               0.0              0.0  0.068966    945aea18       NaN  \n",
       "3          0.482759            2             45           0.000000             0.000000          1.000000               0.0              0.0  0.103448    945aea18       NaN  \n",
       "4          0.482759           39            694           0.052632             0.000000          0.947368               0.0              0.0  0.137931    945aea18       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = mol.read_all_notebooks_(train_dir, LOAD_NUM, PROCESSORS_COUNT)\n",
    "\n",
    "df = pd.concat(stream(np.array_split(df, PROCESSORS_COUNT)).mpmap(mol.extract_features))\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print('-' * 125)\n",
    "\n",
    "# Read Ordering data\n",
    "df_orders = pd.read_csv(\n",
    "    orders_path,\n",
    "    index_col='id',\n",
    ")\n",
    "df_orders['cell_order'] = df_orders['cell_order'].str.split()  # Split the string representation of cell_ids into a list\n",
    "df_orders = df_orders.squeeze(axis=1)\n",
    "\n",
    "\n",
    "# build ranks as integers \n",
    "df = df.join(mol.build_ranks_(df_orders, df, PROCESSORS_COUNT))\n",
    "\n",
    "\n",
    "# Read Ancestors data\n",
    "df = df.reset_index().merge(pd.read_csv(ancestors_path,  index_col='id'), on=[\"id\"])\n",
    "\n",
    "# convert integer ranks to percentages \n",
    "df[\"rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3eb2ab-052d-4dd0-9ac4-03da4c7e9f4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1af4a5-f509-4de8-8763-fd6bc391a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words counts to cover 0.96 is: 129\n",
      "Total number of fetures output from bert: 138\n"
     ]
    }
   ],
   "source": [
    "# for percentages \n",
    "INTREST_PERCENT = 0.96\n",
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "VALIDATION_RATIO = 0.15\n",
    "\n",
    "NOT_GENERATED_COLUMNS = ['id', 'cell_id', 'source', 'cell_type', 'rank', 'ancestor_id', 'parent_id', ]\n",
    "MODEL_USELESS = ['id', 'cell_id', 'cell_type', 'ancestor_id', 'parent_id', ]\n",
    "GENERATED_COLUMNS_COUNT = len(df.drop(['id', 'cell_id', 'source', 'cell_type', 'rank', 'ancestor_id', 'parent_id', ], axis=1).columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BERT_MODEL_NAME = \"microsoft/codebert-base\"\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "# BERT_MODEL_NAME = \"microsoft/graphcodebert-base\"\n",
    "\n",
    "\n",
    "# OPTIMIZER = 'adam'\n",
    "OPTIMIZER = 'nadam'\n",
    "\n",
    "\n",
    "# model run\n",
    "MAX_LENGTH = int(df[df.cell_type == MKDN_TYPE].words_count.quantile(INTREST_PERCENT)) \n",
    "# MAX_LENGTH = 128\n",
    "BERT_OUTPUT_FEATURES = MAX_LENGTH + GENERATED_COLUMNS_COUNT\n",
    "\n",
    "print(\"Words counts to cover {percent} is: {count}\".format(percent=INTREST_PERCENT, count=MAX_LENGTH))\n",
    "print(f'Total number of fetures output from bert: {BERT_OUTPUT_FEATURES}')\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1\n",
    "TOTAL_MAX_LEN = 512\n",
    "ACCUMULATION_SETPS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "465fc851-7dc4-4f2b-af4d-7f88fced939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [151 152 153 154 155]\n"
     ]
    }
   ],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1, test_size=VALIDATION_RATIO, random_state=RANDOM_SEED)\n",
    "\n",
    "def extract_items(ids, data, cell_type):\n",
    "    tmp = data.loc[ids, :].reset_index(drop=True)\n",
    "    return tmp[tmp.cell_type == cell_type]\n",
    "\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids_train, ids_valid = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "print(ids_train[:5], ids_valid[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba1916-9244-4a65-b3e2-8cd7e100c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee91c22b-f832-4691-958c-2712870b8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract markdown cells for each notebook\n",
    "df_train = df.loc[ids_train, :].reset_index(drop=True)\n",
    "df_valid =  df.loc[ids_valid, :].reset_index(drop=True)\n",
    "# print(mkdn_df_train[:5], mkdn_df_valid[:5])\n",
    "\n",
    "\n",
    "# build markdown Dataset\n",
    "train_ds = mol.BDataset(\n",
    "    df_train[df_train.cell_type == MKDN_TYPE], \n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    drop=MODEL_USELESS,\n",
    ")\n",
    "val_ds = mol.BDataset(\n",
    "    df_valid[df_valid.cell_type == MKDN_TYPE], \n",
    "    max_len=MAX_LENGTH, \n",
    "    bert_model_name=BERT_MODEL_NAME, \n",
    "    total_max_len=TOTAL_MAX_LEN,  \n",
    "    drop=MODEL_USELESS,\n",
    ")\n",
    "# print(mkdn_train_ds[0], mkdn_val_ds[0])\n",
    "\n",
    "# build markdown DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=PROCESSORS_COUNT, pin_memory=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=PROCESSORS_COUNT, pin_memory=False, drop_last=False)\n",
    "# print(mkdn_train_loader, mkdn_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8344d3e-2b22-4a92-b30d-4ea548829d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 6.078826 lr:0.001 : 100%|██████████| 67/67 [00:47<00:00,  1.40it/s] \n",
      "100%|██████████| 19/19 [00:34<00:00,  1.82s/it]\n",
      "Validation MAE: 1.10554\n",
      "\n",
      "Final accuracy for markdown is: -0.06248210999795534\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "model = mol.BModel(\n",
    "    BERT_MODEL_NAME, \n",
    "    GENERATED_COLUMNS_COUNT,\n",
    "    # catch_path=models_dir,\n",
    ").cuda()\n",
    "\n",
    "model, y_pred = mol.train(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epochs=EPOCHS, \n",
    "    accumulation_steps=ACCUMULATION_SETPS, \n",
    "    model_name=BERT_MODEL_NAME,\n",
    "    opt='nadam', \n",
    "    path=os.path.join(models_dir, 'markdown_bert_checkpoint.pt')\n",
    ")\n",
    "\n",
    "df_valid[\"pred\"] = df_train.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "df_valid.loc[df_valid.cell_type == MKDN_TYPE, \"pred\"] = y_pred\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "y_dummy = df_valid.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print('Final accuracy for markdown is:', mol.kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "\n",
    "# # best_model_state = deepcopy(mkdn_model.state_dict())\n",
    "# # t.save(best_model_state, f'./pt_models/markdown_model_state_dict.pt')\n",
    "# # t.save(mkdn_model, f'./pt_models/markdown_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0715a-ae21-439c-9eed-3735e2540ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aed180-0fea-44b4-911b-70b439817dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_MAX_LEN = 256\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "code_df_valid['rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'code_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=CD_MAX_LENGTH, \n",
    "    generated_columns_count=GENERATED_COLUMNS_COUNT,\n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=code_df_valid, \n",
    "    drop=MODEL_USELESS,\n",
    ")\n",
    "\n",
    "mkdn_df_valid['rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'markdown_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=MK_MAX_LENGTH,\n",
    "    generated_columns_count=GENERATED_COLUMNS_COUNT,\n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=mkdn_df_valid, \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "vres_df = pd.concat([mkdn_df_valid, code_df_valid], ignore_index=True, ).sort_values(\"rank\").groupby(\"id\")[\"cell_id\"].apply(list)\n",
    "print('Final total accuracy is:', r.kendall_tau(df_orders.loc[vres_df.index], vres_df))\n",
    "\n",
    "display(vres_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5c0cd-8d19-4588-b19b-80e9aca01a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1d626-5a52-4013-89eb-6d1d519c149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print(f\"\\033[94mNumber of notebooks present in test set  = \", len(list(glob.iglob(os.path.join(test_dir, '*.json')))))\n",
    "\n",
    "df_test = r.read_all_notebooks_(test_dir, 4, 2, desc=\"Tests NBs\")\n",
    "\n",
    "df_test = r.extract_features(df_test).reset_index()\n",
    "df_test['rank'] = 0\n",
    "\n",
    "MODEL_USELESS = ['id', 'cell_id', 'cell_type', ]\n",
    "\n",
    "CODE_TYPE = 'code'\n",
    "MKDN_TYPE = 'markdown'\n",
    "\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TOTAL_MAX_LEN = 256\n",
    "\n",
    "df_test.loc[df_test.cell_type == CODE_TYPE, 'rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'code_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=CD_MAX_LENGTH, \n",
    "    generated_columns_count=GENERATED_COLUMNS_COUNT,\n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=df_test[df_test.cell_type == CODE_TYPE], \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "df_test.loc[df_test.cell_type == MKDN_TYPE, 'rank'] = m.predict(\n",
    "    model_path=BERT_MODEL_NAME,\n",
    "    check_point=os.path.join(models_dir, 'markdown_bert_checkpoint.pt'), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    max_len=MK_MAX_LENGTH, \n",
    "    generated_columns_count=GENERATED_COLUMNS_COUNT,\n",
    "    total_max_len=TOTAL_MAX_LEN, \n",
    "    data=df_test[df_test.cell_type == MKDN_TYPE], \n",
    "    drop=MODEL_USELESS\n",
    ")\n",
    "\n",
    "df_test = df_test.sort_values(\"rank\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "df_test.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "display(df_test.head())\n",
    "\n",
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b7c86-0c4f-4d1f-b9cb-fb02b0a4364d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb418e-c1f6-4869-9e3c-1ab06ca93679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d14459-ef30-489c-8018-7ad129fbcf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f15cc8-a69c-4dab-b1ab-174ed13d5b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
