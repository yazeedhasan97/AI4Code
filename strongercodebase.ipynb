{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982e38e6-db5e-44bf-8357-b89195d223b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yazee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDA VERSION: 11.5\n",
      "__CUDNN VERSION: 8302\n",
      "True\n",
      "None\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, os, glob, psutil, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "notebook.tqdm.pandas()\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from pyxtension.streams import stream\n",
    "import swifter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import nltk\n",
    "try:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "except:\n",
    "    print(\"Could't donlowd requaired text data\")\n",
    "\n",
    "print('__CUDA VERSION:', torch.version.cuda)\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.empty_cache())\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    \n",
    "\n",
    "\n",
    "import strongercodebase_v2 as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bc71a2-66d2-4cf2-a638-7d2ae09af538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mNumber of notebooks present in train set  =  139256\n",
      "\u001b[94mNumber of notebooks contribute in training =  1000\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "PROCESSORS_COUNT = psutil.cpu_count(logical=False)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "data_dir = Path('.')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "models_dir = os.path.join(data_dir, 'pt_models')\n",
    "orders_path = os.path.join(data_dir, 'train_orders.csv')\n",
    "ancestors_path = os.path.join(data_dir, 'train_ancestors.csv')\n",
    "\n",
    "MKDN = 'markdown'\n",
    "CODE = 'code'\n",
    "\n",
    "count = len(list(glob.iglob(os.path.join(train_dir, '*.json'))))\n",
    "NUM_TRAIN = int(count * 0.15) + 1 # 0.15\n",
    "NUM_TRAIN = 1000\n",
    "MULTI = PROCESSORS_COUNT * int(str(NUM_TRAIN) [:-2])\n",
    "\n",
    "print(f\"\\033[94mNumber of notebooks present in train set  = \", count)\n",
    "print(f\"\\033[94mNumber of notebooks contribute in training = \", NUM_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3268dfb0-eff8-43f5-9b2a-47ec34188063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████| 1000/1000 [00:06<00:00, 158.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00001756c60be8</th>\n",
       "      <th>1862f0a6</th>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a9e43d6</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038b763d</th>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2eefe0ef</th>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0beab1cd</th>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type                                                                                                                   source\n",
       "id             cell_id                                                                                                                                    \n",
       "00001756c60be8 1862f0a6      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "               2a9e43d6      code  import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cros...\n",
       "               038b763d      code                                                                       import warnings\\nwarnings.filterwarnings('ignore')\n",
       "               2eefe0ef      code                                                                            matplotlib.rcParams.update({'font.size': 14})\n",
       "               0beab1cd      code  def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 50010.78it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df97ec1e5f64798947e86fdcf13e744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cros...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2eefe0ef</td>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>0beab1cd</td>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source      rank  \\\n",
       "0  00001756c60be8  1862f0a6      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...  0.000000   \n",
       "1  00001756c60be8  2a9e43d6      code  import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cros...  0.034483   \n",
       "2  00001756c60be8  038b763d      code                                                                       import warnings\\nwarnings.filterwarnings('ignore')  0.068966   \n",
       "3  00001756c60be8  2eefe0ef      code                                                                            matplotlib.rcParams.update({'font.size': 14})  0.103448   \n",
       "4  00001756c60be8  0beab1cd      code  def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\...  0.137931   \n",
       "\n",
       "  ancestor_id parent_id  \n",
       "0    945aea18       NaN  \n",
       "1    945aea18       NaN  \n",
       "2    945aea18       NaN  \n",
       "3    945aea18       NaN  \n",
       "4    945aea18       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000757b90aaca0</td>\n",
       "      <td>1c301fa2</td>\n",
       "      <td>markdown</td>\n",
       "      <td># analys text similar spacy, networkx notebook demonstr way spaci conduct rapid themat analysi small corpu comments,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ff3e6f37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>import pandas as pd\\nimport spacy\\nimport networkx as nx                        #  a really useful network analysis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007f21ee357b5</td>\n",
       "      <td>e68e6c44</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5d4bdf92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002bcc9e2f9077</td>\n",
       "      <td>c5c6a0a5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h1&gt;introduction&lt;/h1&gt; notebook cover data stich text similar techniques. work databas multipl tables. common `id` `k...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f0446ffd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002bbeec78c962</td>\n",
       "      <td>0329b907</td>\n",
       "      <td>markdown</td>\n",
       "      <td>### import packages:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f31585a0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>import numpy as np #  linear algebra\\nimport pandas as pd #  data processing, CSV file I/O (e.g. pd.read_csv)\\nimpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "0  00001756c60be8  1862f0a6      code  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...   0.0    945aea18   \n",
       "1  000757b90aaca0  1c301fa2  markdown  # analys text similar spacy, networkx notebook demonstr way spaci conduct rapid themat analysi small corpu comments,...   0.0    ff3e6f37   \n",
       "2  0007f21ee357b5  e68e6c44      code  import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...   0.0    5d4bdf92   \n",
       "3  002bcc9e2f9077  c5c6a0a5  markdown  <h1>introduction</h1> notebook cover data stich text similar techniques. work databas multipl tables. common `id` `k...   0.0    f0446ffd   \n",
       "4  002bbeec78c962  0329b907  markdown                                                                                                     ### import packages:   0.0    f31585a0   \n",
       "\n",
       "  parent_id  n_code_cells  n_markdown_cells                                                                                                                    codes  \n",
       "0       NaN            30                28  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...  \n",
       "1       NaN            22                20  import pandas as pd\\nimport spacy\\nimport networkx as nx                        #  a really useful network analysis ...  \n",
       "2       NaN            79                 9  import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...  \n",
       "3       NaN            18                 9  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...  \n",
       "4       NaN            15                10  import numpy as np #  linear algebra\\nimport pandas as pd #  data processing, CSV file I/O (e.g. pd.read_csv)\\nimpor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = ssp.read_all_notebooks_(train_dir, NUM_TRAIN, PROCESSORS_COUNT)\n",
    "display(df.head())\n",
    "print('-' * 125)\n",
    "\n",
    "# Read Ordering data\n",
    "df_orders = pd.read_csv(\n",
    "    orders_path,\n",
    "    index_col='id',\n",
    ")\n",
    "df_orders['cell_order'] = df_orders['cell_order'].str.split()  # Split the string representation of cell_ids into a list\n",
    "df_orders = df_orders.squeeze(axis=1)\n",
    "\n",
    "\n",
    "# build ranks as integers \n",
    "df = df.join(ssp.build_ranks_(df_orders, df, PROCESSORS_COUNT))\n",
    "\n",
    "\n",
    "# Read Ancestors data\n",
    "df = df.reset_index().merge(pd.read_csv(ancestors_path,  index_col='id'), on=[\"id\"])\n",
    "\n",
    "# convert integer ranks to percentages \n",
    "df[\"rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "df = pd.concat(stream(np.array_split(df, PROCESSORS_COUNT)).mpmap(ssp.add_style_specific_counts))\n",
    "\n",
    "df = pd.concat(stream(np.array_split(df, PROCESSORS_COUNT)).mpmap(ssp.get_features)).reset_index(drop=True)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485ad5f1-0a52-4ada-bc70-4d3bc53f0331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5] [ 1 10 17 26 35]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>#  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007f21ee357b5</td>\n",
       "      <td>e68e6c44</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source  rank  \\\n",
       "0  00001756c60be8  1862f0a6      code  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...   0.0   \n",
       "1  0007f21ee357b5  e68e6c44      code  import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...   0.0   \n",
       "\n",
       "   n_code_cells  n_markdown_cells                                                                                                                    codes  \n",
       "0            30                28  #  This Python 3 environment comes with many helpful analytics libraries installed\\n#  It is defined by the kaggle/p...  \n",
       "1            79                 9  import numpy as np \\nimport pandas as pd \\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.naiv...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>n_code_cells</th>\n",
       "      <th>n_markdown_cells</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000757b90aaca0</td>\n",
       "      <td>1c301fa2</td>\n",
       "      <td>markdown</td>\n",
       "      <td># analys text similar spacy, networkx notebook demonstr way spaci conduct rapid themat analysi small corpu comments,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>import pandas as pd\\nimport spacy\\nimport networkx as nx                        #  a really useful network analysis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0029a37d79568a</td>\n",
       "      <td>5ae20870</td>\n",
       "      <td>markdown</td>\n",
       "      <td>notebook' train loop minor issu loss function fork 200+ times.&lt;br/&gt; https://www.kaggle.com/maunish/clrp-pytorch-robe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>!pip install accelerateSEPERATOR_STRIG_TAGimport os\\nimport gc\\nimport sys\\nimport math\\nimport time\\nimport tqdm\\ni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source  rank  \\\n",
       "0  000757b90aaca0  1c301fa2  markdown  # analys text similar spacy, networkx notebook demonstr way spaci conduct rapid themat analysi small corpu comments,...   0.0   \n",
       "1  0029a37d79568a  5ae20870  markdown  notebook' train loop minor issu loss function fork 200+ times.<br/> https://www.kaggle.com/maunish/clrp-pytorch-robe...   0.0   \n",
       "\n",
       "   n_code_cells  n_markdown_cells                                                                                                                    codes  \n",
       "0            22                20  import pandas as pd\\nimport spacy\\nimport networkx as nx                        #  a really useful network analysis ...  \n",
       "1            10                 1  !pip install accelerateSEPERATOR_STRIG_TAGimport os\\nimport gc\\nimport sys\\nimport math\\nimport time\\nimport tqdm\\ni...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VALIDATION_RATIO = 0.15\n",
    "MODEL_USELESS = [ 'ancestor_id', 'parent_id', ] # 'id', 'cell_type',\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=VALIDATION_RATIO, random_state=RANDOM_SEED)\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids_train, ids_valid = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "print(ids_train[:5], ids_valid[:5])\n",
    "\n",
    "# extract code cells for each notebook\n",
    "df_train = df.loc[ids_train, :].reset_index(drop=True).drop(MODEL_USELESS, axis=1)\n",
    "df_valid = df.loc[ids_valid, :].reset_index(drop=True).drop(MODEL_USELESS, axis=1)\n",
    "display(df_train.head(2))\n",
    "display(df_valid.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40770e7b-8327-44d1-86e1-14eb5cae0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256 \n",
    "EPOCHS = 1 # 5\n",
    "TOTAL_MAX_LEN = 512\n",
    "\n",
    "# BERT_MODEL_NAME = \"microsoft/codebert-base\"\n",
    "BERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "# BERT_MODEL_NAME = \"microsoft/graphcodebert-base\"\n",
    "\n",
    "# OPTIMIZER = 'adam'\n",
    "OPTIMIZER = 'nadam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f6f43b-4a25-4376-906b-54d503b474bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#largest_divisor = 0\n",
    "#for i in range(2, len(df_train)):\n",
    "#    if largest_divisor >= 10: break\n",
    "#    if len(df_train) % i == 0:\n",
    "#        largest_divisor = i\n",
    "#BATCH_SIZE = largest_divisor\n",
    "#print(BATCH_SIZE)\n",
    "BATCH_SIZE = 16\n",
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229324b5-b973-4813-82e8-fef5deeabfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39805 6709\n",
      "2487 420\n"
     ]
    }
   ],
   "source": [
    "train_ds = ssp.BDataset(\n",
    "    df_train, \n",
    "    bert_model_name=BERT_MODEL_NAME,\n",
    "    max_len=MAX_LENGTH,\n",
    "    total_max_len=TOTAL_MAX_LEN,\n",
    ")\n",
    "val_ds = ssp.BDataset(\n",
    "    df_valid,    \n",
    "    bert_model_name=BERT_MODEL_NAME,\n",
    "    max_len=MAX_LENGTH,\n",
    "    total_max_len=TOTAL_MAX_LEN,\n",
    ")\n",
    "print(len(train_ds), len(val_ds), )\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    pin_memory=False, \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=PROCESSORS_COUNT, \n",
    "    pin_memory=False, \n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(len(train_loader), len(val_loader), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97155907-8c2d-4fc3-a624-3f4b00a122c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.698312 lr:0.001 :   0%|          | 1/2487 [00:36<25:01:53, 36.25s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 8.00 GiB total capacity; 4.63 GiB already allocated; 1.71 GiB free; 4.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m ssp\u001b[38;5;241m.\u001b[39mBModel(BERT_MODEL_NAME)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m----> 2\u001b[0m model, ypred \u001b[38;5;241m=\u001b[39m \u001b[43mssp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msingle_bert_checkpoint.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_valid\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrank(pct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ypred\n",
      "File \u001b[1;32mE:\\AI4Code\\strongercodebase_v2.py:263\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, epochs, opt, model_name, patience, accumulation_steps, path)\u001b[0m\n\u001b[0;32m    259\u001b[0m inputs, target \u001b[38;5;241m=\u001b[39m read_data(data)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# pred = model(*inputs)\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, target)\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# loss = rank_loss(pred, target)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\AI4Code\\strongercodebase_v2.py:467\u001b[0m, in \u001b[0;36mBModel.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m--> 467\u001b[0m     dbert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_layers_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dbert\n",
      "File \u001b[1;32mE:\\AI4Code\\strongercodebase_v2.py:482\u001b[0m, in \u001b[0;36mBModel.linear_layers_forward\u001b[1;34m(self, ids, masks, fts)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinear_layers_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids, masks, fts):\n\u001b[1;32m--> 482\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistill_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]))        \n\u001b[0;32m    483\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(torch\u001b[38;5;241m.\u001b[39mcat((x[:, \u001b[38;5;241m0\u001b[39m, :], fts), \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    484\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprelu1(x)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:567\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:345\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    343\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_state,)\n\u001b[1;32m--> 345\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:283\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    292\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:223\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[1;32m--> 223\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    224\u001b[0m context \u001b[38;5;241m=\u001b[39m unshape(context)  \u001b[38;5;66;03m# (bs, q_length, dim)\u001b[39;00m\n\u001b[0;32m    225\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_lin(context)  \u001b[38;5;66;03m# (bs, q_length, dim)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 8.00 GiB total capacity; 4.63 GiB already allocated; 1.71 GiB free; 4.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = ssp.BModel(BERT_MODEL_NAME).cuda()\n",
    "model, ypred = ssp.train(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epochs=EPOCHS, \n",
    "    path=os.path.join(models_dir, 'single_bert_checkpoint.pt'),\n",
    "    accumulation_steps=2,\n",
    ")\n",
    "\n",
    "df_valid[\"pred\"] = df_valid.groupby([\"id\"])[\"rank\"].rank(pct=True)\n",
    "df_valid[\"pred\"] = ypred\n",
    "y_dummy = df_valid.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print('Final accuracy for code is:', ssp.kendall_tau(df_orders.loc[y_dummy.index], y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab998bb2-22c1-4fc3-87c0-f9b1754587c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "# sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "# sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427b944-7f8d-4738-8f82-d0be611b9280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
